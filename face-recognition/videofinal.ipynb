{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\haha\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# 屏蔽Jupyter的warning訊息\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Utilities相關函式庫\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2, 3'\n",
    "from os.path import join as pjoin\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from scipy import misc\n",
    "from scipy.spatial import distance # 用來計算歐幾里德距離 (euclidean)\n",
    "\n",
    "# 圖像處理相關函式庫\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 多維向量處理相關函式庫\n",
    "import numpy as np\n",
    "\n",
    "# 深度學習相關函式庫\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# 機械學習\n",
    "from sklearn.svm import LinearSVC\n",
    "import joblib\n",
    "\n",
    "# 模型序列化函式庫\n",
    "import pickle\n",
    "\n",
    "# 專案相關函式庫\n",
    "import facenet\n",
    "import detect_face\n",
    "import visualization_utils as vis_utils\n",
    "from scipy import misc\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 專案的根目錄路徑\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# 訓練/驗證用的資料目錄\n",
    "DATA_PATH = os.path.join(ROOT_DIR, \"data\")\n",
    "\n",
    "# 模型的資料目錄\n",
    "MODEL_PATH = os.path.join(ROOT_DIR, \"model\")\n",
    "\n",
    "# MTCNN的模型\n",
    "MTCNN_MODEL_PATH = os.path.join(MODEL_PATH, \"mtcnn\")\n",
    "\n",
    "# FaceNet的模型\n",
    "FACENET_MODEL_PATH = os.path.join(MODEL_PATH, \"facenet\",\"20170512-110547\",\"20170512-110547.pb\")\n",
    "\n",
    "# Classifier的模型\n",
    "SVM_MODEL_PATH = os.path.join(MODEL_PATH, \"svm\", \"lfw_svm_classifier.pkl\")\n",
    "\n",
    "# 訓練/驗證用的圖像資料目錄\n",
    "IMG_IN_PATH = os.path.join(DATA_PATH, \"pic\")\n",
    "\n",
    "# 訓練/驗證用的圖像資料目錄\n",
    "IMG_OUT_PATH = os.path.join(DATA_PATH, \"pic_crops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 反序列化相關可重覆使用的資料\n",
    "# \"人臉embedding\"的資料\n",
    "with open(os.path.join(DATA_PATH,'lfw_emb_features.pkl'), 'rb') as emb_features_file:\n",
    "    emb_features =pickle.load(emb_features_file)\n",
    "\n",
    "# \"人臉embedding\"所對應的標籤(label)的資料\n",
    "with open(os.path.join(DATA_PATH,'lfw_emb_labels.pkl'), 'rb') as emb_lables_file:\n",
    "    emb_labels =pickle.load(emb_lables_file)\n",
    "\n",
    "# \"標籤(label)對應到人臉名稱的字典的資料\n",
    "with open(os.path.join(DATA_PATH,'lfw_emb_labels_dict.pkl'), 'rb') as emb_lables_dict_file:\n",
    "    emb_labels_dict =pickle.load(emb_lables_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dict = {} # key 是label, value是embedding list\n",
    "for feature,label in zip(emb_features, emb_labels):\n",
    "    # 檢查key有沒有存在\n",
    "    if label in emb_dict:\n",
    "        emb_dict[label].append(feature)\n",
    "    else:\n",
    "        emb_dict[label] = [feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算兩個人臉特徵（Facenet Embedding 128 bytes vector)的歐式距離\n",
    "def calc_dist(face1_emb, face2_emb):    \n",
    "    return distance.euclidean(face1_emb, face2_emb)\n",
    "\n",
    "face_distance_threshold = 1.1\n",
    "\n",
    "# 計算一個人臉的embedding是不是歸屬某一個人\n",
    "# 根據Google Facenet的論文, 透過計算兩個人臉embedding的歐氏距離\n",
    "# 0: 代表為同一個人臉 , threshold <1.1 代表兩個人臉非常相似 \n",
    "def is_same_person(face_emb, face_label, threshold=1.1):\n",
    "    emb_distances = []\n",
    "    emb_features = emb_dict[face_label]\n",
    "    for i in range(len(emb_features)):\n",
    "        emb_distances.append(calc_dist(face_emb, emb_features[i]))\n",
    "    \n",
    "    # 取得平均值\n",
    "    if np.mean(emb_distances) > threshold: # threshold <1.1 代表兩個人臉非常相似 \n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minsize = 40  # 最小的臉部的大小\n",
    "threshold = [0.6, 0.7, 0.7]  # 三個網絡(P-Net, R-Net, O-Net)的閥值\n",
    "factor = 0.709  # scale factor\n",
    "\n",
    "margin = 44 # 在裁剪人臉時的邊框margin\n",
    "image_size = 182 # 160 + 22\n",
    "\n",
    "batch_size = 1000\n",
    "input_image_size = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x1cf49cec048>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_g = tf.Graph().as_default()\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6)\n",
    "\n",
    "# 創建Tensorflow Session物件\n",
    "tf_sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "\n",
    "# 把這個Session設成預設的session\n",
    "tf_sess.as_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\haha\\Desktop\\face-recognition\\detect_face.py:212: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\haha\\Desktop\\face-recognition\\detect_face.py:214: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\haha\\Desktop\\face-recognition\\detect_face.py:215: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "pnet, rnet, onet = detect_face.create_mtcnn(tf_sess, MTCNN_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading feature extraction model\n",
      "Model filename: C:\\Users\\haha\\Desktop\\face-recognition\\model\\facenet\\20170512-110547\\20170512-110547.pb\n",
      "WARNING:tensorflow:From C:\\Users\\haha\\Desktop\\face-recognition\\facenet.py:442: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "Face embedding size:  128\n"
     ]
    }
   ],
   "source": [
    "print('Loading feature extraction model')\n",
    "modeldir =  FACENET_MODEL_PATH #'/..Path to Pre-trained model../20170512-110547/20170512-110547.pb'\n",
    "facenet.load_model(modeldir)\n",
    "\n",
    "# 取得模型的輸入與輸出的佔位符\n",
    "images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "embedding_size = embeddings.get_shape()[1]\n",
    "\n",
    "# 打印\"人臉特徵向量\"的向量大小\n",
    "print(\"Face embedding size: \", embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load classifier file-> C:\\Users\\haha\\Desktop\\face-recognition\\model\\svm\\lfw_svm_classifier.pkl\n",
      "LinearSVC(C=1)\n"
     ]
    }
   ],
   "source": [
    "classifier_filename = SVM_MODEL_PATH\n",
    "\n",
    "with open(classifier_filename, 'rb') as svm_model_file:\n",
    "    (face_svc_classifier, face_identity_names) = pickle.load(svm_model_file)\n",
    "    HumanNames = face_identity_names    #訓練時的人臉的身份\n",
    "    \n",
    "    print('load classifier file-> %s' % classifier_filename)\n",
    "    print(face_svc_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('1.mp4')\n",
    "flag=1\n",
    "name = []\n",
    "while(flag):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow(\"capture\", frame)     \n",
    "    cv2.waitKey(10)\n",
    "    name = []\n",
    "    find_results = []\n",
    "    #frame = cv2.imread(face_input)\n",
    "    draw = frame.copy() # 複製原圖像\n",
    "    frame = frame[:,:,::-1] # 把BGR轉換成RGB\n",
    "        # 步驟 #1.偵測人臉位置\n",
    "        # 偵測人臉的邊界框\n",
    "    bounding_boxes, _ = detect_face.detect_face(frame, minsize, pnet, rnet, onet, threshold, factor)\n",
    "    nrof_faces = bounding_boxes.shape[0] # 被偵測到的臉部總數\n",
    "    if nrof_faces > 0: # 如果有偵測到人臉\n",
    "    \n",
    "        det = bounding_boxes[:, 0:4].astype(int) \n",
    "        img_size = np.asarray(frame.shape)[0:2] \n",
    "  \n",
    "        cropped = []\n",
    "        scaled = []\n",
    "        scaled_reshape = []\n",
    "        bb = np.zeros((nrof_faces,4), dtype=np.int32)\n",
    "        total = 0\n",
    "    # 步驟 #2.擷取人臉特徵\n",
    "        for i in range(nrof_faces):\n",
    "            emb_array = np.zeros((1, embedding_size))\n",
    "\n",
    "            x1 = bb[i][0] = det[i][0]\n",
    "            y1 = bb[i][1] = det[i][1]\n",
    "            x2 = bb[i][2] = det[i][2]\n",
    "            y2 = bb[i][3] = det[i][3]\n",
    "        \n",
    "        # inner exception\n",
    "            if bb[i][0] <= 0 or bb[i][1] <= 0 or bb[i][2] >= len(frame[0]) or bb[i][3] >= len(frame):\n",
    "                continue\n",
    "        \n",
    "        # **人臉圖像的前處理 **\n",
    "            \n",
    "        # 根據邊界框的座標來進行人臉的裁剪\n",
    "            cropped.append(frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :])\n",
    "            cropped[i] = facenet.flip(cropped[i], False)\n",
    "            scaled.append(misc.imresize(cropped[i], (image_size, image_size), interp='bilinear'))\n",
    "            scaled[i] = cv2.resize(scaled[i], (input_image_size,input_image_size),\n",
    "                               interpolation=cv2.INTER_CUBIC)\n",
    "            scaled[i] = facenet.prewhiten(scaled[i])\n",
    "            scaled_reshape.append(scaled[i].reshape(-1,input_image_size,input_image_size,3))       \n",
    "            feed_dict = {images_placeholder: scaled_reshape[i], phase_train_placeholder: False}\n",
    "        \n",
    "        # 進行臉部特徵擷取\n",
    "            emb_array[0, :] = tf_sess.run(embeddings, feed_dict=feed_dict)\n",
    "        \n",
    "        # 步驟 #3.進行人臉識別分類\n",
    "            face_id_idx = face_svc_classifier.predict(emb_array)   \n",
    "            \n",
    "            if is_same_person(emb_array, int(face_id_idx), 1.1):            \n",
    "                face_id_name = HumanNames[int(face_id_idx)] # 取出人臉的名字\n",
    "                bb_color = vis_utils.STANDARD_COLORS[i] # 給予不同的顏色\n",
    "                bb_fontcolor = 'black'\n",
    "                flag=0\n",
    "                name.append(face_id_name)\n",
    "                total+=1\n",
    "            else:\n",
    "                face_id_name = 'Unknown'\n",
    "                bb_color = 'BlueViolet' # 給予紅色\n",
    "                bb_fontcolor = 'white'\n",
    "        if total < 2 :\n",
    "                flag=1;\n",
    "        \n",
    "cap.release()\n",
    "#haha='data/id/'+ face_id_name + '.jpg'          \n",
    "#cv2.destroyAllWindows()\n",
    "for i in name:\n",
    "    haha='data/id/'+ i + '.jpg'  \n",
    "    img = Image.open(haha)\n",
    "    img.show()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
